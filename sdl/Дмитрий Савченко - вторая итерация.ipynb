{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6ce8c4",
   "metadata": {},
   "source": [
    "<font color='blue' size=5><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "<font color='blue'>Привет, Дмитрий! Меня зовут Григорий Звездин, и я буду проверять этот проект. Спасибо за проделанную работу! Предлагаю общаться на «ты».</font>\n",
    "\n",
    "<font color='blue'>Я буду использовать различные цвета, чтобы было удобнее воспринимать мои комментарии:</font>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<font color='blue'>синий текст - просто текст комментария</font>\n",
    "\n",
    "<font color='green'>✔️ и зеленый текст - все отлично</font>\n",
    "\n",
    "<font color='orange'>⚠️ и оранжевый текст - сделано все правильно, однако есть рекомендации, на что стоит обратить внимание</font>\n",
    "\n",
    "<font color='red'>❌ и красный текст - есть недочеты</font>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<font color='blue'>Пожалуйста, не удаляй мои комментарии в случае возврата работы, так будет проще разобраться, какие были недочеты, а также сразу увидеть исправленное. </font>\n",
    "\n",
    "Ответы на мои комментарии лучше тоже помечать.\n",
    "Например: <font color='blue'><b>Комментарий студента</b></font>\n",
    "\n",
    "<font color='blue'><b>Давай смотреть, что получилось!</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a4f53",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Предисловие:</b> \n",
    "<p>Привет</p>\n",
    "<p>т.к. в Я.Практикуме последнюю тему решили нориально не давать, я Х.З., что тут нужно делать и как правильно, будем разбираться вместе))</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145ee3b5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Теперь вопрос правильно я преобразование сделал из картинки в вектор или нет:</b> \n",
    "<p>Загрузчик я сделал, но сильно сомневаюсь, что правльно связал имена картинок и их вектор</p>\n",
    "<p>И модель теперь вообще не понимает что я ей показываю=)))</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65944b4c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Я не умею исользовать Керас:</b> \n",
    "\n",
    "<p>Много раз пишу о том что я ХЗ как предсказывать оценку что-то написал но оно не работает как делать не знаю</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0c4042",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера v2: </b></font> ✔️\\\n",
    "<font color='green'>Привет! Давай смотреть\\\n",
    "Мои комментарии в этой итерации будут отмечены версией v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686bd09a",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>Хорошо, вперед :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f9108d",
   "metadata": {
    "cellId": "pbwq209p45adtxfy5ofecd",
    "deletable": false,
    "editable": false,
    "execution_id": "7cb94123-6481-41de-973a-91abe63db303",
    "tags": [
     "5643b276-1159-4b34-85a5-eeadeed9ff48"
    ]
   },
   "source": [
    "# Прекод\n",
    "\n",
    "# Сборный проект-4\n",
    "\n",
    "Вам поручено разработать демонстрационную версию поиска изображений по запросу.\n",
    "\n",
    "Для демонстрационной версии нужно обучить модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — покажет, насколько текст и картинка подходят друг другу.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные лежат в папке `/datasets/image_search/`.\n",
    "\n",
    "В файле `train_dataset.csv` находится информация, необходимая для обучения: имя файла изображения, идентификатор описания и текст описания. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `train_images` содержатся изображения для тренировки модели.\n",
    "\n",
    "В файле `CrowdAnnotations.tsv` — данные по соответствию изображения и описания, полученные с помощью краудсорсинга. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "3. Доля людей, подтвердивших, что описание соответствует изображению.\n",
    "4. Количество человек, подтвердивших, что описание соответствует изображению.\n",
    "5. Количество человек, подтвердивших, что описание не соответствует изображению.\n",
    "\n",
    "В файле `ExpertAnnotations.tsv` содержатся данные по соответствию изображения и описания, полученные в результате опроса экспертов. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "\n",
    "3, 4, 5 — оценки трёх экспертов.\n",
    "\n",
    "Эксперты ставят оценки по шкале от 1 до 4, где 1 — изображение и запрос совершенно не соответствуют друг другу, 2 — запрос содержит элементы описания изображения, но в целом запрос тексту не соответствует, 3 — запрос и текст соответствуют с точностью до некоторых деталей, 4 — запрос и текст соответствуют полностью.\n",
    "\n",
    "В файле `test_queries.csv` находится информация, необходимая для тестирования: идентификатор запроса, текст запроса и релевантное изображение. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `test_images` содержатся изображения для тестирования модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c142fc7",
   "metadata": {
    "cellId": "n6vkjcacwu39w29bfocxt",
    "execution_id": "1b731a18-3394-4b62-b3f7-018692c2d6de"
   },
   "source": [
    "## 1. Исследовательский анализ данных\n",
    "\n",
    "Наш датасет содержит экспертные и краудсорсинговые оценки соответствия текста и изображения.\n",
    "\n",
    "В файле с экспертными мнениями для каждой пары изображение-текст имеются оценки от трёх специалистов. Для решения задачи вы должны эти оценки агрегировать — превратить в одну. Существует несколько способов агрегации оценок, самый простой — голосование большинства: за какую оценку проголосовала большая часть экспертов (в нашем случае 2 или 3), та оценка и ставится как итоговая. Поскольку число экспертов меньше числа классов, может случиться, что каждый эксперт поставит разные оценки, например: 1, 4, 2. В таком случае данную пару изображение-текст можно исключить из датасета.\n",
    "\n",
    "Вы можете воспользоваться другим методом агрегации оценок или придумать свой.\n",
    "\n",
    "В файле с краудсорсинговыми оценками информация расположена в таком порядке: \n",
    "\n",
    "1. Доля исполнителей, подтвердивших, что текст **соответствует** картинке. \n",
    "2. Количество исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "3. Количество исполнителей, подтвердивших, что текст **не соответствует** картинке.\n",
    "\n",
    "После анализа экспертных и краудсорсинговых оценок выберите либо одну из них, либо объедините их в одну по какому-то критерию: например, оценка эксперта принимается с коэффициентом 0.6, а крауда — с коэффициентом 0.4.\n",
    "\n",
    "Ваша модель должна возвращать на выходе вероятность соответствия изображения тексту, поэтому целевая переменная должна иметь значения от 0 до 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afda40f",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>Когда прогонял у себя, добавлял:\n",
    "```\n",
    "! pip install gensim -U\n",
    "! curl https://code.s3.yandex.net/datasets/dsplus_integrated_project_4.zip --output data.zip\n",
    "! unzip -o -q /content/data.zip\n",
    "! mv to_upload source\n",
    "```\n",
    "\n",
    "Только в последних версия gensim есть vector_size, до этого был просто size\\\n",
    "А загрузка позволяет вручную в колаб не подгружать данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3b97cc",
   "metadata": {
    "cellId": "exl6m83oldxqlu1vq1s6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dmitry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/dmitry/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/dmitry/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/dmitry/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# То что читал попутно\n",
    "# https://thinkingneuron.com/how-to-classify-text-using-word2vec/\n",
    "# https://builtin.com/machine-learning/nlp-word2vec-python\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "\n",
    "english_stopwords = set(nltk_stopwords.words('english'))\n",
    "null_stopwords = []\n",
    "vect = CountVectorizer()\n",
    "tf_vect = TfidfVectorizer()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd0f58",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>Круто, что указываешь, какие материалы изучал в процессе. Такие комментарии полезны\\\n",
    "    А вот комменты с неиспользуемым кодом лучше убрать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03c154f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import copy\n",
    "# https://russianblogs.com/article/37751553118/\n",
    "# https://medium.com/@nina95dan/simple-image-classification-with-resnet-50-334366e7311a\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8e60c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 04:14:26.391124: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, AveragePooling2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140b4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем данные именуем столбцы\n",
    "df_t = pd.read_csv('source/train_dataset.csv')\n",
    "df_c = pd.read_csv('source/CrowdAnnotations.tsv', sep='\\t', names=['image', 'query_id', 'proc', 't', 'f'])\n",
    "df_e = pd.read_csv('source/ExpertAnnotations.tsv', sep='\\t', names=['image', 'query_id', 'e1', 'e2', 'e3'])\n",
    "\n",
    "#display('Датасет для тернировки')\n",
    "#display(df_t.head(5))\n",
    "#display(df_t.info())\n",
    "#display('Датасет оценок краудсорсинга')\n",
    "#display(df_c.head(5))\n",
    "#display(df_c.info())\n",
    "#display('Датасет оценок экспертов')\n",
    "#display(df_e.head(5))\n",
    "#display(df_e.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2f6773",
   "metadata": {},
   "source": [
    "__Вывод:__ Из выше представленных данных видно, что типы данных определились верно, пустые строки отсутствуют."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23507d",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ❌\\\n",
    "<font color='red'>Добавь, пожалуйста, изучение данных, хотя бы посмотреть первые строки и инфо\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>Комментарий студента V1:</b> \n",
    "<p>Добавил.</p></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7be881",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера v2: </b></font> ✔️\\\n",
    "<font color='green'>Хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6525f7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>e3</th>\n",
       "      <th>el</th>\n",
       "      <th>em</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3207358897_bfa61fa3c6.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3286822339_5535af6b93.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5817</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>2981702521_2459f2c1c4.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5818</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>2985679744_75a7102aab.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5819</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>3150742439_b8a352e1e0.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5820</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>3375070563_3c290a7991.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>486917990_72bd4069af.jpg#2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5696 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image                     query_id  e1  e2  e3  el  \\\n",
       "0     1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2   1   1   1   1   \n",
       "1     1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2   1   1   2   2   \n",
       "2     1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2   1   1   2   2   \n",
       "3     1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2   1   2   2   2   \n",
       "4     1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2   1   1   2   2   \n",
       "...                         ...                          ...  ..  ..  ..  ..   \n",
       "5817   997722733_0cb5439472.jpg  2981702521_2459f2c1c4.jpg#2   1   1   1   1   \n",
       "5818   997722733_0cb5439472.jpg  2985679744_75a7102aab.jpg#2   1   1   1   1   \n",
       "5819   997722733_0cb5439472.jpg  3150742439_b8a352e1e0.jpg#2   1   1   2   2   \n",
       "5820   997722733_0cb5439472.jpg  3375070563_3c290a7991.jpg#2   1   1   1   1   \n",
       "5821   997722733_0cb5439472.jpg   486917990_72bd4069af.jpg#2   3   3   3   1   \n",
       "\n",
       "      em  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      2  \n",
       "4      1  \n",
       "...   ..  \n",
       "5817   1  \n",
       "5818   1  \n",
       "5819   1  \n",
       "5820   1  \n",
       "5821   3  \n",
       "\n",
       "[5696 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Функция покажет количество уникальных оценок в датасете\n",
    "def len_list_in_col(row:pd.Series)->int:\n",
    "    result = len(set(row))\n",
    "    return result\n",
    "# Возьмём предложенный метод\n",
    "df_e['el'] = df_e[['e1', 'e2', 'e3']].values.tolist()\n",
    "df_e['el'] = df_e['el'].apply(len_list_in_col)\n",
    "df_e = df_e[df_e['el']!=3].copy()\n",
    "df_e['em'] = df_e[['e1', 'e2', 'e3']].mode(axis=1)[0]\n",
    "# Ну всё оценки экспертов лежат в столбце em\n",
    "df_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "428ce9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>e3</th>\n",
       "      <th>el</th>\n",
       "      <th>em_x</th>\n",
       "      <th>proc</th>\n",
       "      <th>t</th>\n",
       "      <th>f</th>\n",
       "      <th>em_y</th>\n",
       "      <th>em_a</th>\n",
       "      <th>scaler_em_a</th>\n",
       "      <th>scaler_em_x</th>\n",
       "      <th>scaler_em_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>434792818_56375e203f.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084040636_97d9633581.jpg</td>\n",
       "      <td>256085101_2c2617c5d0.jpg#2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1084040636_97d9633581.jpg</td>\n",
       "      <td>3396157719_6807d52a81.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>979383193_0a542a059d.jpg</td>\n",
       "      <td>3244747165_17028936e0.jpg#2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>979383193_0a542a059d.jpg</td>\n",
       "      <td>3482062809_3b694322c4.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>2985679744_75a7102aab.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>3150742439_b8a352e1e0.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>486917990_72bd4069af.jpg#2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2258 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image                     query_id  e1  e2  e3  el  \\\n",
       "0     1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2   1   1   1   1   \n",
       "1     1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2   1   1   2   2   \n",
       "2     1056338697_4f7d7ce270.jpg   434792818_56375e203f.jpg#2   1   1   2   2   \n",
       "3     1084040636_97d9633581.jpg   256085101_2c2617c5d0.jpg#2   2   3   3   2   \n",
       "4     1084040636_97d9633581.jpg  3396157719_6807d52a81.jpg#2   1   2   2   2   \n",
       "...                         ...                          ...  ..  ..  ..  ..   \n",
       "2253   979383193_0a542a059d.jpg  3244747165_17028936e0.jpg#2   2   2   2   1   \n",
       "2254   979383193_0a542a059d.jpg  3482062809_3b694322c4.jpg#2   1   2   2   2   \n",
       "2255   997722733_0cb5439472.jpg  2985679744_75a7102aab.jpg#2   1   1   1   1   \n",
       "2256   997722733_0cb5439472.jpg  3150742439_b8a352e1e0.jpg#2   1   1   2   2   \n",
       "2257   997722733_0cb5439472.jpg   486917990_72bd4069af.jpg#2   3   3   3   1   \n",
       "\n",
       "      em_x      proc  t  f  em_y  em_a  scaler_em_a  scaler_em_x  scaler_em_y  \n",
       "0        1  0.000000  0  3   1.0   1.0     0.000000     0.000000     0.000000  \n",
       "1        1  0.000000  0  3   1.0   1.0     0.000000     0.000000     0.000000  \n",
       "2        1  0.000000  0  3   1.0   1.0     0.000000     0.000000     0.000000  \n",
       "3        3  0.333333  1  2   2.0   2.6     0.533333     0.666667     0.333333  \n",
       "4        2  0.000000  0  3   1.0   1.6     0.200000     0.333333     0.000000  \n",
       "...    ...       ... .. ..   ...   ...          ...          ...          ...  \n",
       "2253     2  0.000000  0  3   1.0   1.6     0.200000     0.333333     0.000000  \n",
       "2254     2  0.000000  0  3   1.0   1.6     0.200000     0.333333     0.000000  \n",
       "2255     1  0.000000  0  3   1.0   1.0     0.000000     0.000000     0.000000  \n",
       "2256     1  0.000000  0  3   1.0   1.0     0.000000     0.000000     0.000000  \n",
       "2257     3  0.333333  1  2   2.0   2.6     0.533333     0.666667     0.333333  \n",
       "\n",
       "[2258 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# т.к. думать лень рашим в лоб, преобразуем оценки людей в эквивалент экспертных\n",
    "converter_crowd_to_expert = {\n",
    "    '[3, 0]':4,\n",
    "    '[2, 1]':3,\n",
    "    '[1, 2]':2,\n",
    "    '[0, 3]':1\n",
    "}\n",
    "\n",
    "def crowd_to_exp(row:pd.Series, conv)->int:\n",
    "    result = conv.get(str(row), None)\n",
    "    return result\n",
    "df_c['em'] = df_c[['t', 'f']].values.tolist()\n",
    "df_c['em'] = df_c['em'].apply(crowd_to_exp,  **{'conv':converter_crowd_to_expert})\n",
    "\n",
    "# Объеденим оценки экспертов и еще какието в один столбец\n",
    "df_m = pd.merge(df_e, df_c, how='inner', on=['image','query_id'])\n",
    "df_m['em_a'] = df_m['em_x'] * .6 + df_m['em_y'] * .4\n",
    "# Преобразую всё что могу к значениям 0, 1\n",
    "df_m['scaler_em_a'] = minmax_scale(df_m['em_a'], feature_range=(0, 1))\n",
    "df_m['scaler_em_x'] = minmax_scale(df_m['em_x'], feature_range=(0, 1))\n",
    "df_m['scaler_em_y'] = minmax_scale(df_m['em_y'], feature_range=(0, 1))\n",
    "\n",
    "df_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9fdc35",
   "metadata": {
    "cellId": "9h91oxwx86d7i8rqt5miv4",
    "execution_id": "4401a0e8-fd2b-479b-9e84-6ffafbcead47"
   },
   "source": [
    "## 2. Проверка данных\n",
    "\n",
    "В некоторых странах, где работает ваша компания, действуют ограничения по обработке изображений: поисковым сервисам и сервисам, предоставляющим возможность поиска, запрещено без разрешения родителей или законных представителей предоставлять любую информацию, в том числе, но не исключительно тексты, изображения, видео и аудио, содержащие описание, изображение или запись голоса детей. Ребёнком считается любой человек, не достигший 16 лет.\n",
    "\n",
    "В вашем сервисе строго следуют законам стран, в которых работают. Поэтому при попытке посмотреть изображения, запрещённые законодательством, вместо картинок показывается дисклеймер:\n",
    "\n",
    "> This image is unavailable in your country in compliance with local laws\n",
    "> \n",
    "\n",
    "Однако у вас в PoC нет возможности воспользоваться данным функционалом. Поэтому все изображения, которые нарушают данный закон, нужно удалить из обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d35b30ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мои стоп слова\n",
    "my_stop = ['boy', 'child', 'girl', 'baby', 'todler', 'kid']\n",
    "# Лемматизация с моими стоп словами нужна для маркировки стоп лов знаком 16+\n",
    "def get_lemm_word(sentence:str, stop_words:list, stop_words_my:list)->str:\n",
    "    lemm_word_list = []\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence).lower()\n",
    "    word_list = nltk.word_tokenize(sentence)\n",
    "    for word in word_list:\n",
    "        lemm_word = lemmatizer.lemmatize(word)\n",
    "        lemm_word_list.append(lemm_word)\n",
    "    lemm_word_list = set(lemm_word_list) - set(stop_words)\n",
    "    result = ' '.join(list(lemm_word_list))\n",
    "    for word in stop_words_my:\n",
    "        if word in result:\n",
    "            result = '16+'\n",
    "            break\n",
    "    return result\n",
    "\n",
    "# Основной лемматизатор\n",
    "def lemmer(sentence:str, stop_words:list)->str:\n",
    "    lemm_word_list = []\n",
    "    word_list = nltk.word_tokenize(sentence)\n",
    "    for word in word_list:\n",
    "        lemm_word = lemmatizer.lemmatize(word.lower())\n",
    "        in_stop_words=False\n",
    "        for m in stop_words:\n",
    "            if m == lemm_word:\n",
    "                in_stop_words = True\n",
    "                break\n",
    "        if in_stop_words == False:\n",
    "            lemm_word_list.append(lemm_word)\n",
    "    result = ' '.join(list(lemm_word_list))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b49dbc",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>Хорошо, и слова выбраны верно. Можно добавить в список baby, todler, kid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0e93364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5m/zj2yj9bd5m55jbrzd0_nfd6m0000gn/T/ipykernel_55624/1613038779.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_t['query_clean'] = df_t['query_text'].str.replace(r'[^\\w\\s]', '').str.lower()\n"
     ]
    }
   ],
   "source": [
    "df_t['lemm'] = df_t['query_text'].apply(get_lemm_word, **{'stop_words':english_stopwords,\n",
    "                                                         'stop_words_my':my_stop})\n",
    "\n",
    "df_t['query_clean'] = df_t['query_text'].str.replace(r'[^\\w\\s]', '').str.lower()\n",
    "\n",
    "df_t['query_clean_lemm'] = df_t['query_clean'].apply(lemmer, **{'stop_words':english_stopwords})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd8e19",
   "metadata": {
    "cellId": "ggxcvhmhcm9rshysbjoo4n",
    "execution_id": "d7935f99-48c0-42b8-a227-dd2b2d9b70fc"
   },
   "source": [
    "## 3. Векторизация изображений\n",
    "\n",
    "Перейдём к векторизации изображений.\n",
    "\n",
    "Самый примитивный способ — прочесть изображение и превратить полученную матрицу в вектор. Такой способ нам не подходит: длина векторов может быть сильно разной, так как размеры изображений разные. Поэтому стоит обратиться к свёрточным сетям: они позволяют \"выделить\" главные компоненты изображений. Как это сделать? Нужно выбрать какую-либо архитектуру, например ResNet-18, посмотреть на слои и исключить полносвязные слои, которые отвечают за конечное предсказание. При этом можно загрузить модель данной архитектуры, предварительно натренированную на датасете ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4edb30c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://russianblogs.com/article/37751553118/\n",
    "paths = Path('source/train_images').rglob('*.jpg')\n",
    "paths_img_for_test = Path('source/test_images').rglob('*.jpg')\n",
    "# Получим в список пути картинок\n",
    "jpg_paths = list(map(str, paths))\n",
    "jpg_paths_img_for_test = list(map(str, paths_img_for_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f188d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем картинки в вектор\n",
    "def img_to_vec_2(img_path:str, w, h):\n",
    "    im_name = img_path.split('/')[-1]\n",
    "    wh = width_img\n",
    "    ht = height_img\n",
    "    m = np.array(Image.open(path).convert('RGB').resize((wh,ht)))\n",
    "    return im_name, m.reshape(1,wh,ht,3)\n",
    "\n",
    "# Та функция которая по идее получает вектора изображений но по какойто причине они почти все одинаковые\n",
    "vector_len_for_img_and_text = 300\n",
    "def create_model(input_shape):\n",
    "    backbone = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(Dense(vector_len_for_img_and_text, activation='relu'))\n",
    "    return model\n",
    "\n",
    "def create_model_2_old(input_shape):\n",
    "    backbone = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(vector_len_for_img_and_text, activation='relu'))\n",
    "    return model\n",
    "\n",
    "# Модель котораую предложил ты.\n",
    "def create_model_2(input_shape):\n",
    "    backbone = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(Flatten())\n",
    "    return model\n",
    "# Возьму модель Кирилла т.к. с субботы выпытывал её у него.\n",
    "def create_model_2_kirill(input_shape):\n",
    "    backbone = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b8ad8b",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера v2: </b></font> ❌\\\n",
    "<font color='red'>Почти верно, но, как я писал до этого, нам не нужен полносвязный слой\\\n",
    "Итог получается такой:\n",
    "```python\n",
    "def create_model_2(input_shape):\n",
    "    backbone = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(Flatten())\n",
    "    return model\n",
    "```\n",
    "<div class=\"alert alert-block alert-info\"><b>Это проблема на самом деле V2:</b> \n",
    "<p>Кирилл Талалаев (преподаватель) и ты дают противоположенные функции для решения этой проблемы)))</p>\n",
    "<p>Преподаватель сказал мне что Flatten не нужен</p></div>\n",
    "    \n",
    "```python\n",
    "def create_model_2(input_shape):\n",
    "    backbone = ResNet50(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "    backbone.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    return model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a305979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"width_img = height_img = 224\\nimg_vec = dict()\\nmodel = create_model((width_img, height_img, 3))\\nfor path in jpg_paths:\\n    n, v = img_to_vec_2(path, width_img, height_img)\\n    r50_v = model(v)\\n    img_vec[n] = r50_v.numpy()[0]\\nprint('Part test')\\nimg_vec_2 = dict()\\nfor path in jpg_paths_img_for_test:\\n    n, v = img_to_vec_2(path, width_img, height_img)\\n    r50_v = model(v)\\n    img_vec_2[n] = r50_v.numpy()[0]\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''width_img = height_img = 224\n",
    "img_vec = dict()\n",
    "model = create_model((width_img, height_img, 3))\n",
    "for path in jpg_paths:\n",
    "    n, v = img_to_vec_2(path, width_img, height_img)\n",
    "    r50_v = model(v)\n",
    "    img_vec[n] = r50_v.numpy()[0]\n",
    "print('Part test')\n",
    "img_vec_2 = dict()\n",
    "for path in jpg_paths_img_for_test:\n",
    "    n, v = img_to_vec_2(path, width_img, height_img)\n",
    "    r50_v = model(v)\n",
    "    img_vec_2[n] = r50_v.numpy()[0]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989c3151",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ❌\\\n",
    "<font color='red'>\n",
    "    Имеет смысл воспользоваться загрузчиком из темы Компьютерное зрение в Keras - Загрузчики данных\\\n",
    "    У тебя есть полносвязные слои, а нам нужна свертка (верхушка не нужна). Параметр include_top=False убирает верхушку самого реснета, значит, тебе нужно убрать все, кроме backbone, и будет отлично (тема ResNet в Keras [GPU] про параметры модели)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c2e541",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Загрузчик V1:</b> \n",
    "<p>Создал загрузчик, читает данные из нужной папки.</p>\n",
    "<p>Связывает имена через datagen_train.filenames.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5679eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n",
      "Found 100 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 04:14:35.062363: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end 100%\n",
      "end 100%\n"
     ]
    }
   ],
   "source": [
    "# https://practicum.yandex.ru/learn/data-scientist-plus/courses/1770e0c9-1225-4554-b336-96c1fc166bc0/sprints/6563/topics/a8313445-b2d5-40a1-8c78-4cf33bcbb227/lessons/b827be1d-cd01-4461-8f9c-ff12e7f36545/\n",
    "width_img = height_img = 32\n",
    "datagen = ImageDataGenerator() \n",
    "\n",
    "datagen_train = datagen.flow_from_directory(\n",
    "    # папка, в которой хранится датасет\n",
    "    'source',\n",
    "    # папка из которой берем картики и присваиваем ей класс\n",
    "    classes=['train_images'],\n",
    "    # к какому размеру приводить изображения\n",
    "    target_size=(width_img, height_img), \n",
    "    # размер батча\n",
    "    batch_size=32,\n",
    "    # в каком виде выдавать метки классов\n",
    "    class_mode=None,\n",
    "    # фиксируем генератор случайных чисел (от англ. random seed)\n",
    "    seed=12345,\n",
    "    shuffle=False)\n",
    "\n",
    "datagen_test = datagen.flow_from_directory(\n",
    "    # папка, в которой хранится датасет\n",
    "    'source',\n",
    "    # папка из которой берем картики и присваиваем ей класс\n",
    "    classes=['test_images'],\n",
    "    # к какому размеру приводить изображения\n",
    "    target_size=(width_img, height_img), \n",
    "    # размер батча\n",
    "    batch_size=32,\n",
    "    # в каком виде выдавать метки классов\n",
    "    class_mode=None,\n",
    "    # фиксируем генератор случайных чисел (от англ. random seed)\n",
    "    seed=12345,\n",
    "    shuffle=False)\n",
    "# Посомтрим какие классы у нас есть в датаген\n",
    "#datagen_train.class_indices\n",
    "file_names_train = [f.split('/')[-1] for f in datagen_train.filenames]\n",
    "file_names_test = [f.split('/')[-1] for f in datagen_test.filenames]\n",
    "\n",
    "def get_vec_img(mod, features_gen, features_name):\n",
    "    counter_samples = 0\n",
    "    count_samle = features_gen.samples\n",
    "    result = dict()\n",
    "    while counter_samples < count_samle:\n",
    "        bat = next(features_gen)\n",
    "        for item in bat:\n",
    "            fn = features_name[counter_samples]\n",
    "            ft = item.reshape(1, width_img, height_img, 3)\n",
    "            # Буду отправлять по одному т.к. только так имена и вектора совпадают\n",
    "            # При отправке пачкой результатов.\n",
    "            # Ясно, что весь смысл загрузчика теряется, но я его использовать и не думал=)))\n",
    "            result[fn] = mod(ft, training=False).numpy()[0].tolist() # Списки хранить удобнее в Pandas ячеках\n",
    "            counter_samples = counter_samples+1 # На M1 работает чуть ли не в 2 раза быстрее чеи += 1\n",
    "            print(f'{round(100 * counter_samples / count_samle)}%', end='\\r', flush=True)\n",
    "    print('end 100%')\n",
    "    return result\n",
    "\n",
    "\n",
    "model_2 = create_model_2((width_img, height_img, 3))\n",
    "\n",
    "img_vec_3 = get_vec_img(model_2, datagen_train, file_names_train)\n",
    "img_vec_4 = get_vec_img(model_2, datagen_test, file_names_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc3539b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_vec_4_dc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img_vec_4 \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[43mimg_vec_4_dc\u001b[49m)\n\u001b[1;32m      2\u001b[0m img_vec_3 \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(img_vec_3_dc)\n\u001b[1;32m      4\u001b[0m len_v4 \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_vec_4_dc' is not defined"
     ]
    }
   ],
   "source": [
    "img_vec_4 = copy.deepcopy(img_vec_4_dc)\n",
    "img_vec_3 = copy.deepcopy(img_vec_3_dc)\n",
    "\n",
    "len_v4 = []\n",
    "len_v3 = []\n",
    "for key, value in img_vec_4.items():\n",
    "    len_v4.append(len(value))\n",
    "    a = key \n",
    "    \n",
    "for key, value in img_vec_3.items():\n",
    "    len_v3.append(len(value))\n",
    "    a = key \n",
    "print(min(len_v4)-max(len_v4))\n",
    "print(min(len_v3)-max(len_v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa74f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import copy\n",
    "#img_vec_4_dc = copy.deepcopy(img_vec_4)\n",
    "#img_vec_3_dc = copy.deepcopy(img_vec_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91309176",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера v2: </b></font> ❌\\\n",
    "<font color='red'>Не совсем так, батч позволяет побить данные, чтобы все влезло в память, у тебя он выбран слишком большим\\\n",
    "С помощью next ты получаешь только первый батч ( может, в этом причина такого большого батча?)\\\n",
    "    Чтобы выполнить верно, сделаем константу BATCH_SIZE, например, 10. Зададим везде параметр batch_size=BATCH_SIZE\\\n",
    "    Затем можем написать ф-цию для получения предсказаний. Я написал пример для тебя:\n",
    "```python\n",
    "def get_predictions(keras_model, datagen):\n",
    "    batches = 0\n",
    "    for features_batch in datagen:\n",
    "        if batches == 0:\n",
    "          keras_vec_batch = keras_model(features_batch, training=False).numpy()\n",
    "        else:\n",
    "          keras_vec_batch = np.vstack((keras_vec_batch, keras_model(features_batch, training=False).numpy()))\n",
    "        batches += 1\n",
    "        print(batches, keras_vec_batch.shape)\n",
    "        if batches >= datagen.samples / BATCH_SIZE:\n",
    "                # Сам цикл не остановится, поэтому прервем\n",
    "                # https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "                break\n",
    "    return keras_vec_batch\n",
    "```\n",
    "    \n",
    "<div class=\"alert alert-block alert-info\"><b>PIL V2:</b> \n",
    "<p>Мне кажется PIL был значительно короче в плане написания кода и практичнее в плане использования</p>\n",
    "<p>Решение с загрузчиком не выглядит как то чем имеет смысл воспользоваться =))))</p>\n",
    "<p>Теперь у меня аналог PIL только с использованием Keras 🤣</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10593abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Переехало к генераторам\n",
    "#keras_vec_train = model_2(features_train, training=False).numpy()\n",
    "#keras_vec_test = model_2(features_test, training=False).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33262629",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера v2: </b></font> ❌\\\n",
    "<font color='red'>Здесь мы можем воспользоваться готовой моделью, обучать не нужно. Добавь, пожалуйста, параметр ```training=False```. Пример выше\n",
    "    \n",
    "<div class=\"alert alert-block alert-info\"><b>Исправил V2:</b> \n",
    "<p>Добавил к генераторам</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d875cefb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Возможно ошибка V1:</b> \n",
    "<p>Вот не факт что я через zip верно связал вектора и имена файлов возможно есть более верный метод</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "173c04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Переехало к генераторам\n",
    "#img_vec_3 = dict(zip(file_names_train,keras_vec_train))\n",
    "#img_vec_4 = dict(zip(file_names_test,keras_vec_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb19c1f",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ❌\\\n",
    "<font color='red'>Тебе нужно добавить shuffle=False в datagen.flow_from_directory\\\n",
    "    https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "<div class=\"alert alert-block alert-info\"><b>Исправил V2:</b> \n",
    "<p>Добавил к генераторам</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30bb86",
   "metadata": {
    "cellId": "z8evfugfch8wpstvnxv0t",
    "execution_id": "028ade1d-49fe-4110-8b13-3c1aecdaa142"
   },
   "source": [
    "## 4. Векторизация текстов\n",
    "\n",
    "Следующий этап — векторизация текстов. Вы можете поэкспериментировать с несколькими способами векторизации текстов:\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- \\*трансформеры (например Bert)\n",
    "\n",
    "\\* — если вы изучали трансформеры в спринте Машинное обучение для текстов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e22c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_t[df_t['lemm']!='16+'][['image', 'query_id', 'query_clean_lemm']].copy()\n",
    "#features_train_tfidf = tf_vect.fit_transform(df_clean['query_clean_lemm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae2a0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(df_clean['query_clean_lemm'].str.split(' '), min_count=1, vector_size=vector_len_for_img_and_text)\n",
    "def row_to_vec(words):\n",
    "    result = word2vec.wv[words.split(' ')].mean(axis=0).tolist()\n",
    "    return result\n",
    "features_train_word2vec = df_clean['query_clean_lemm'].apply(row_to_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd5e505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = []\n",
    "\n",
    "for i in features_train_word2vec:\n",
    "    len_list.append(len(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbc27cf",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>Хорошо"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae691f",
   "metadata": {
    "cellId": "yci1zcmnsacl720fr75sb",
    "execution_id": "5ecfa9d5-3913-4fb3-a33e-99bab3798577"
   },
   "source": [
    "## 5. Объединение векторов\n",
    "\n",
    "Подготовьте данные для обучения: объедините векторы изображений и векторы текстов с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46b590e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['vec_img'] = df_clean['image'].map(img_vec_3)\n",
    "df_clean['word2vec'] = features_train_word2vec\n",
    "df_clean.reset_index(inplace=True, drop=True)\n",
    "df_clean2 = df_clean.copy()\n",
    "#df_clean['tf_idf'] = pd.Series(features_train_tfidf.toarray().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0956e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ну будем думать, что угадал, но задача странная на объеденение векторов или я что-то не так понял\n",
    "df_union = pd.merge(df_m[['image', 'query_id', 'scaler_em_a']], \n",
    "                    df_clean[['image', 'query_id', 'vec_img', 'word2vec']], \n",
    "                    how='inner', on=['image','query_id'])\n",
    "df_union.dropna(inplace=True)\n",
    "# Не угадал :)))))))))))\n",
    "def extend_2_col(row, col1, col2):\n",
    "    result = row[col1] + row[col2]\n",
    "    return result\n",
    "df_union['all_vec'] = df_union.apply(extend_2_col, **{'col1':'vec_img','col2':'word2vec', 'axis':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa39c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_union[['query_id', 'scaler_em_a', 'vec_img', 'word2vec', 'all_vec']].copy()\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bbd7997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "len_w2v = []\n",
    "for i in df['vec_img']:\n",
    "    len_w2v.append(len(i))\n",
    "print(min(len_w2v)-max(len_w2v))\n",
    "len_vimg = []\n",
    "for i in df['all_vec']:\n",
    "    len_vimg.append(len(i))\n",
    "print(min(len_vimg)-max(len_vimg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9cf152",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>А почему угадайка? Все верно, есть два df - один с векторами, другой с оценкой, делаешь merge inner по image и query_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf27a3",
   "metadata": {
    "cellId": "97c9jj3s2zjj62vznivsk",
    "execution_id": "1a2d7233-0c79-479a-be63-5787145e3b48"
   },
   "source": [
    "## 6. Обучение модели предсказания соответствия\n",
    "\n",
    "Для обучения разделите датасет на тренировочную и тестовую выборки. Простое случайное разбиение не подходит: нужно исключить попадание изображения и в обучающую, и в тестовую выборки.\n",
    "Для того чтобы учесть изображения при разбиении, можно воспользоваться классом [GroupShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html) из библиотеки sklearn.model_selection.\n",
    "\n",
    "Код ниже разбивает датасет на тренировочную и тестовую выборки в пропорции 7:3 так, что строки с одинаковым значением 'group_column' будут содержаться либо в тестовом, либо в тренировочном датасете.\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n",
    "train_indices, test_indices = next(gss.split(X=df.drop(columns=['target']), y=df['target'], groups=df['group_column']))\n",
    "train_df, test_df = df.loc[train_indices], df.loc[test_indices]\n",
    "\n",
    "```\n",
    "\n",
    "Какую модель использовать — выберите самостоятельно. Также вам предстоит выбрать метрику качества либо реализовать свою."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69407b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>scaler_em_a</th>\n",
       "      <th>vec_img</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>all_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>434792818_56375e203f.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 1.8533728122711182, 0.0, 0.0, 1.36430060...</td>\n",
       "      <td>[0.033765606582164764, 0.12567871809005737, 0....</td>\n",
       "      <td>[0.0, 1.8533728122711182, 0.0, 0.0, 1.36430060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256085101_2c2617c5d0.jpg#2</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>[0.0, 4.034458160400391, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.016657916828989983, 0.05736476182937622, 0....</td>\n",
       "      <td>[0.0, 4.034458160400391, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3396157719_6807d52a81.jpg#2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>[0.0, 4.034458160400391, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.01862158440053463, 0.06194028630852699, 0.0...</td>\n",
       "      <td>[0.0, 4.034458160400391, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1425069308_488e5fcf9d.jpg#2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.026876477524638176, 0.10640222579240799, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2410320522_d967f0b75c.jpg#2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.03184913843870163, 0.11478441953659058, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>293327462_20dee0de56.jpg#2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.026563482359051704, 0.09557177126407623, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3582742297_1daa29968e.jpg#2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.030097998678684235, 0.11044153571128845, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>229862312_1a0ba19dab.jpg#2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.031188219785690308, 0.10802992433309555, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>416106657_cab2a107a5.jpg#2</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.032459113746881485, 0.11328871548175812, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2894217628_f1a4153dca.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.29459649324417114, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.03113306313753128, 0.1159488782286644, 0.01...</td>\n",
       "      <td>[0.0, 0.29459649324417114, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3044500219_778f9f2b71.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.29459649324417114, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.025024671107530594, 0.09345541149377823, 0....</td>\n",
       "      <td>[0.0, 0.29459649324417114, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       query_id  scaler_em_a  \\\n",
       "0    434792818_56375e203f.jpg#2     0.000000   \n",
       "1    256085101_2c2617c5d0.jpg#2     0.533333   \n",
       "2   3396157719_6807d52a81.jpg#2     0.200000   \n",
       "3   1425069308_488e5fcf9d.jpg#2     0.200000   \n",
       "4   2410320522_d967f0b75c.jpg#2     0.400000   \n",
       "5    293327462_20dee0de56.jpg#2     0.333333   \n",
       "6   3582742297_1daa29968e.jpg#2     0.400000   \n",
       "7    229862312_1a0ba19dab.jpg#2     0.400000   \n",
       "8    416106657_cab2a107a5.jpg#2     0.866667   \n",
       "9   2894217628_f1a4153dca.jpg#2     0.000000   \n",
       "10  3044500219_778f9f2b71.jpg#2     0.000000   \n",
       "\n",
       "                                              vec_img  \\\n",
       "0   [0.0, 1.8533728122711182, 0.0, 0.0, 1.36430060...   \n",
       "1   [0.0, 4.034458160400391, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "2   [0.0, 4.034458160400391, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "3   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9   [0.0, 0.29459649324417114, 0.0, 0.0, 0.0, 0.0,...   \n",
       "10  [0.0, 0.29459649324417114, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                             word2vec  \\\n",
       "0   [0.033765606582164764, 0.12567871809005737, 0....   \n",
       "1   [0.016657916828989983, 0.05736476182937622, 0....   \n",
       "2   [0.01862158440053463, 0.06194028630852699, 0.0...   \n",
       "3   [0.026876477524638176, 0.10640222579240799, 0....   \n",
       "4   [0.03184913843870163, 0.11478441953659058, 0.0...   \n",
       "5   [0.026563482359051704, 0.09557177126407623, 0....   \n",
       "6   [0.030097998678684235, 0.11044153571128845, 0....   \n",
       "7   [0.031188219785690308, 0.10802992433309555, 0....   \n",
       "8   [0.032459113746881485, 0.11328871548175812, 0....   \n",
       "9   [0.03113306313753128, 0.1159488782286644, 0.01...   \n",
       "10  [0.025024671107530594, 0.09345541149377823, 0....   \n",
       "\n",
       "                                              all_vec  \n",
       "0   [0.0, 1.8533728122711182, 0.0, 0.0, 1.36430060...  \n",
       "1   [0.0, 4.034458160400391, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "2   [0.0, 4.034458160400391, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "3   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "7   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "9   [0.0, 0.29459649324417114, 0.0, 0.0, 0.0, 0.0,...  \n",
       "10  [0.0, 0.29459649324417114, 0.0, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4bd510d",
   "metadata": {
    "cellId": "v1ntb27jt4z9fazi1y8me"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n",
    "train_indices, test_indices = next(gss.split(X=df.drop(columns=['scaler_em_a']), y=df['scaler_em_a'], groups=df['scaler_em_a']))\n",
    "train_df, test_df = df.loc[train_indices], df.loc[test_indices]\n",
    "\n",
    "#min_vector_len_for_resize = min(train_df['vec_img'][0].shape[0], train_df['word2vec'][0].shape[0])\n",
    "#y_train = np.array(train_df['vec_img'].to_list())\n",
    "#x_train = np.array(train_df['word2vec'].to_list())\n",
    "\n",
    "#y_test = np.array(test_df['vec_img'].to_list())\n",
    "#x_test = np.array(test_df['word2vec'].to_list())\n",
    "\n",
    "y_train = np.array(train_df['scaler_em_a'])\n",
    "x_train = np.array(train_df['all_vec'].to_list())\n",
    "\n",
    "y_test = np.array(test_df['scaler_em_a'])\n",
    "x_test = np.array(test_df['all_vec'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7166ea1",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера v2: </b></font> ❌\\\n",
    "<font color='red'>Тут есть альтернативное решение. У тебя таргет при делении - это оценка, а затем картинка. И можно ведь предсказать именно оценку\\\n",
    "Сделай y_train и y_test scaler_em_a, a x_train и x_test - vec_img и word2vec (можно попробовать либо раздельно их сделать, либо один столбец, объединив вектора с помощью np.hstack)\\\n",
    "Так задача упростится, мы сможем предсказывать оценку соответствия, а не вектор. Заметь, что тогда сменится и метрика.\\\n",
    "Логика работы функции в шаге 7 станет такой:\n",
    "* На вход приходит текст\n",
    "* Производится векторизация\n",
    "* Фичами становятся вектора изображений и этот 1 входной текст (для всех изображений)\n",
    "* Предсказывается оценка\n",
    "* Выбирается тот случай, где предсказанная оценка лучшая\n",
    "* На экран выводится входной текст и изображение, которое в паре с текстом входным, показало лучшую оценку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3f7d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_for_predict_vector_3(input_len, output_len):\n",
    "    m=Sequential()\n",
    "    m.add(Dense(units=10,input_dim=input_len))\n",
    "    m.add(Dense(1000, activation='relu'))\n",
    "    m.add(Dense(200, activation='relu'))\n",
    "    #m.add(Dropout(.1))\n",
    "    m.add(Dense(output_len, activation='relu'))\n",
    "    m.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "    return m\n",
    "x_len = x_train[0].shape[0]\n",
    "y_len = 1\n",
    "#model2 = create_model_for_predict_vector_2(x_len, y_len)\n",
    "model3 = create_model_for_predict_vector_3(x_len, y_len)\n",
    "#model4 = create_model_for_predict_vector_4(x_len, y_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc862c36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.9060 - val_loss: 12.5283\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.9060 - val_loss: 12.5283\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.9060 - val_loss: 12.5283\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.9060 - val_loss: 12.5283\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.9060 - val_loss: 12.5283\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.9060 - val_loss: 12.5283\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.9060 - val_loss: 12.5283\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.9060 - val_loss: 12.5283\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.9060 - val_loss: 12.5283\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.9060 - val_loss: 12.5283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13e1efb50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model2.fit(x_train, y_train, validation_data=(x_test,y_test), batch_size=5, epochs=100)\n",
    "model3.fit(x_train, y_train, validation_data=(x_test,y_test), batch_size=100, epochs=10)\n",
    "#model4.fit(x_train, y_train, validation_data=(x_test,y_test), batch_size=100, epochs=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d039d487",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ✔️\\\n",
    "<font color='green'>Отлично"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb61cd9",
   "metadata": {
    "cellId": "tbnfwg686jpxjdsw7cqbl",
    "execution_id": "5e14c3be-a481-438e-a979-0f4621acea44"
   },
   "source": [
    "## 7. Тестирование модели\n",
    "\n",
    "Настало время протестировать модель. Для этого получите эмбеддинги для всех тестовых изображений из папки `test_images`, выберите случайные 10 запросов из файла `test_queries.csv` и для каждого запроса выведите наиболее релевантное изображение. Сравните визуально качество поиска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0913eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если в словаре нет слова то меняем его на нулевой вектор)\n",
    "def row_to_vec_2(words):\n",
    "    result = np.array([np.ones(vector_len_for_img_and_text)])\n",
    "    for word in words.split(' '):\n",
    "        if word in word2vec.wv:\n",
    "            result = np.append(result, [word2vec.wv.get_vector(word)], axis = 0)\n",
    "        else:\n",
    "            result = np.append(result,[np.zeros(vector_len_for_img_and_text)], axis = 0)\n",
    "    result = result[1:].mean(axis=0).tolist()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd860a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt = pd.read_csv('source/test_queries.csv', sep='|')\n",
    "df_tt.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "df_tt['lemm'] = df_tt['query_text'].apply(get_lemm_word, **{'stop_words':english_stopwords,\n",
    "                                                         'stop_words_my':my_stop})\n",
    "\n",
    "df_tt['query_clean'] = df_tt['query_text'].str.replace(r'[^\\w\\s]', '').str.lower()\n",
    "\n",
    "df_tt['query_clean_lemm'] = df_tt['query_clean'].apply(lemmer, **{'stop_words':english_stopwords})\n",
    "df_tt['query_clean_lemm'] = df_tt['query_clean'].apply(lemmer, **{'stop_words':english_stopwords})\n",
    "features_train_word2vec = df_tt['query_clean_lemm'].apply(row_to_vec_2)\n",
    "df_tt['word2vec'] = features_train_word2vec\n",
    "\n",
    "df_tt = df_tt[df_tt['lemm']!='16+'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3360242",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ⚠️\\\n",
    "<font color='orange'>Можно преобразования обернуть в функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047fd94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt['vec_img'] = df_tt['image'].map(img_vec_4)\n",
    "def extend_2_col_2(row, col1, my_list):\n",
    "    result = row[col1] + my_list\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_for_test = list(df_tt.sample(10).index)\n",
    "id_str_for_test = list_for_test[0]\n",
    "#str_query_for_test = np.array([df_tt['word2vec'][id_str_for_test]])\n",
    "#predict_img = model3.predict(str_query_for_test)\n",
    "df_tt['all_vec'] = df_tt.apply(extend_2_col, **{'col1':'vec_img','col2':'word2vec', 'axis':1})\n",
    "df_tt['all_vec'] = df_tt.apply(extend_2_col_2, **{'col1':'vec_img',\n",
    "                                                  'my_list':df_tt['word2vec'][id_str_for_test],\n",
    "                                                  'axis':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9021b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_to_pred = np.array(df_tt['all_vec'].to_list())\n",
    "predict_img = model3.predict(x_to_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt['ocenka'] = predict_img\n",
    "df_tt['ocenka'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7050d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_query_for_test = np.array([df_tt['all_vec'][id_str_for_test]])\n",
    "predict_img = model3.predict(str_query_for_test)\n",
    "predict_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f05d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_L2_vec(row, pred_img):\n",
    "    result = np.linalg.norm(row - pred_img, ord=2)\n",
    "    return result\n",
    "\n",
    "def get_distance_mean_vec_img(row, pred_img):\n",
    "    result = abs(row.sum() - pred_img.sum())\n",
    "    return result\n",
    "\n",
    "def test_get_predict(data, id_pred, mod):\n",
    "    str_query_for_test = np.array([df_tt['word2vec'][id_pred]])\n",
    "    predict_img = mod.predict(str_query_for_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    data['L2'] = df_tt['vec_img'].apply(get_distance_L2_vec, **{'pred_img':predict_img})\n",
    "    data['sum_vec_img'] = data['vec_img'].apply(get_distance_mean_vec_img, **{'pred_img':predict_img})\n",
    "\n",
    "    name = df_tt.sort_values('L2', ascending=True)[:1]['image'].values[0] # Предсказанная картинка\n",
    "    query_text = df_tt.sort_values('L2', ascending=True)[:1]['query_text'].values[0] #  Предсказанный запрос\n",
    "\n",
    "    #data.sort_values('L2', ascending=True)\n",
    "    return  query_text, name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116e5e1",
   "metadata": {},
   "source": [
    "__Описание выбора метрики:__  \n",
    "В качестве метрики использую самое короткое расстояние между вектором реальной картинки и вектором предсказанной картинки мне кажется, что я так получу максимально близкий результат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97563df",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Комментарий ревьюера: </b></font> ❌\\\n",
    "<font color='red'>Хорошо, метрика выбрана. Добавь, пожалуйста, обоснование её выбора. Почему ты выбрал именно такой подход?\\\n",
    "    Не очень понятно, в чем задумка предсказанного запроса. Сделай описание предполагаемого алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3793a926",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for item in list_for_test:\n",
    "    tp = 1 #позиция оригинала\n",
    "    pp = 4 #позиция предсказания\n",
    "    \n",
    "    img_query_text, img_name = test_get_predict(df_tt, item, model3)\n",
    "    img_original = Image.open(f'source/test_images/{df_tt[\"image\"][item]}')\n",
    "    img_predict = Image.open(f'source/test_images/{img_name}')\n",
    "\n",
    "    text_original = df_tt[\"query_text\"][item]\n",
    "    text_predict = img_query_text\n",
    "\n",
    "    plt.figure(figsize=(17,17))\n",
    "    plt.subplot(5,4,tp);\n",
    "\n",
    "    plt.title(text_original)\n",
    "    plt.axis ('off')\n",
    "    plt.imshow(img_original)\n",
    "\n",
    "    plt.subplot(5,4,pp)\n",
    "    plt.title(f'predict {text_predict}')\n",
    "    plt.axis ('off')\n",
    "    plt.imshow(img_predict);\n",
    "    tp *=5\n",
    "    pp *=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ce0811",
   "metadata": {},
   "source": [
    "<font color='blue'><b>Итоговый комментарий ревьюера</b></font>\\\n",
    "<font color='green'>Проект действительно напряжный, но большая часть пути пройдена! </font>\n",
    "\n",
    "<font color='blue'>Что можно сделать лучше:</font>\n",
    "<ul><font color='red'>1) Добавить загрузчик</font></ul>\n",
    "<ul><font color='red'>2) Убрать полносвязные слои для векторизации</font></ul>\n",
    "<ul><font color='red'>3) Добавить больше наблюдений (просмотров данных и размерностей) и выводов</font></ul>\n",
    "<ul><font color='red'>4) Описать выбор метрики</font></ul>\n",
    "\n",
    "<font color='blue'><b>Спасибо, жду твоих исправлений и комментариев!</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059dec79",
   "metadata": {
    "cellId": "dnvdkzzxdpet1yc4m64cx",
    "execution_id": "3e367f6a-97e3-4ed7-9b73-39ed363fd2b7"
   },
   "source": [
    "## 8. Выводы\n",
    "\n",
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Исследовательский анализ данных выполнен\n",
    "- [ ]  Проверены экспертные оценки и краудсорсинговые оценки\n",
    "- [ ]  Из датасета исключены те объекты, которые выходят за рамки юридических ограничений\n",
    "- [ ]  Изображения векторизованы\n",
    "- [ ]  Текстовые запросы векторизованы\n",
    "- [ ]  Данные корректно разбиты на тренировочную и тестовую выборки\n",
    "- [ ]  Предложена метрика качества работы модели\n",
    "- [ ]  Предложена модель схожести изображений и текстового запроса\n",
    "- [ ]  Модель обучена\n",
    "- [ ]  По итогам обучения модели сделаны выводы\n",
    "- [ ]  Проведено тестирование работы модели\n",
    "- [ ]  По итогам тестирования визуально сравнили качество поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb403f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2544,
    "start_time": "2022-09-08T14:51:49.796Z"
   },
   {
    "duration": 49,
    "start_time": "2022-09-08T14:58:27.207Z"
   },
   {
    "duration": 54,
    "start_time": "2022-09-08T14:58:42.136Z"
   },
   {
    "duration": 92,
    "start_time": "2022-09-08T14:58:51.822Z"
   },
   {
    "duration": 62,
    "start_time": "2022-09-08T14:59:38.542Z"
   },
   {
    "duration": 50,
    "start_time": "2022-09-08T14:59:52.595Z"
   },
   {
    "duration": 57,
    "start_time": "2022-09-08T14:59:55.634Z"
   },
   {
    "duration": 59,
    "start_time": "2022-09-08T15:00:14.891Z"
   }
  ],
  "celltoolbar": "Отсутствует",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "notebookId": "e47b60f7-b2b4-44ee-beb3-b44a93eaf068",
  "notebookPath": "precode.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
